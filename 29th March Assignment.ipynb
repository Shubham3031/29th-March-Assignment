{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f8962b-92f1-4ef7-a874-ac8533e4382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Ans.\n",
    "\n",
    "Lasso Regression, also known as L1 regularization, is a type of linear regression technique used for\n",
    "feature selection and regularization. In Lasso Regression, the objective is to minimize the sum of\n",
    "squared errors (SSE) between the predicted and actual values of the dependent variable, subject to \n",
    "a constraint on the sum of the absolute values of the model coefficients.\n",
    "\n",
    "The L1 regularization penalty term added to the SSE function acts as a constraint, limiting the size\n",
    "of the coefficients and forcing some of them to be exactly zero. As a result, Lasso Regression can be \n",
    "used to perform feature selection by shrinking the coefficients of less important variables to zero, \n",
    "effectively removing them from the model.\n",
    "\n",
    "Compared to other regression techniques, such as Ridge Regression (L2 regularization) or Ordinary Least\n",
    "Squares (OLS) Regression, Lasso Regression has some distinct advantages.\n",
    "\n",
    "Firstly, it can handle high-dimensional datasets with many features, and automatically select the most\n",
    "relevant features for the model. This is particularly useful when dealing with datasets where the number of\n",
    "features is much larger than the number of observations, which can cause overfitting in other regression\n",
    "techniques.\n",
    "\n",
    "Secondly, Lasso Regression can improve the interpretability of the model, as it explicitly identifies the\n",
    "most important variables and removes irrelevant ones from the model. This can help to simplify the model\n",
    "and make it easier to understand and explain.\n",
    "\n",
    "Finally, Lasso Regression can be more robust to outliers in the data, as the regularization penalty helps\n",
    "to reduce the impact of extreme values on the model coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731805c-9310-4d80-be1a-12300dd78f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Ans.\n",
    "\n",
    "The main advantage of using Lasso Regression in feature selection is that it can automatically \n",
    "select the most relevant features for the model and discard the irrelevant ones, which can improve the \n",
    "model's accuracy and interpretability.\n",
    "\n",
    "Lasso Regression uses a regularization penalty that adds a constraint on the sum of the absolute values\n",
    "of the model coefficients. This constraint forces some of the coefficients to be exactly zero, \n",
    "effectively removing the corresponding features from the model. As a result, Lasso Regression can \n",
    "perform feature selection by shrinking the coefficients of less important variables to zero, and\n",
    "keeping only the most relevant features in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d5a615-41ee-4792-8f67-db08c59c07e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Ans.\n",
    "\n",
    "The coefficients of a Lasso Regression model can  be interpreted as the estimated \n",
    "effect of each feature on the target variable, holding all other variables constant.\n",
    "A positive coefficient indicates that an increase in the corresponding feature value \n",
    "leads to an increase in the target variable value, while a negative coefficient indicates the opposite. \n",
    "The magnitude of the coefficient indicates the strength of the effect, with larger coefficients implying\n",
    "a stronger impact on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1a1c55-f267-4dea-8caa-6dc45b405f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Ans.\n",
    "\n",
    "The alpha parameter controls the degree of regularization applied to the model.\n",
    "\n",
    "There are two common ways to set the alpha parameter in Lasso Regression:\n",
    "\n",
    "Grid Search: In grid search, a range of alpha values is specified, and the model's performance is evaluated\n",
    "for each value. The alpha value that produces the best performance is selected as the optimal value.\n",
    "\n",
    "Cross-Validation: In cross-validation, the data is split into multiple folds, and the model is trained and\n",
    "tested on each fold. The alpha value that produces the best average performance across all folds is selected\n",
    "as the optimal value.\n",
    "\n",
    "The alpha parameter affects the performance of the Lasso Regression model in the following ways:\n",
    "\n",
    "Regularization strength: The alpha parameter controls the strength of regularization applied to the model.\n",
    "Higher values of alpha result in stronger regularization, which shrinks the coefficients towards zero, \n",
    "resulting in a simpler model with fewer features. Lower values of alpha result in weaker regularization, \n",
    "allowing the model to fit more complex relationships between the features and the target variable.\n",
    "\n",
    "Bias-variance tradeoff: The alpha parameter also affects the bias-variance tradeoff of the model. \n",
    "Increasing the value of alpha increases the bias of the model, reducing its ability to fit the training data.\n",
    "However, it also reduces the variance of the model, making it less susceptible to overfitting. \n",
    "Decreasing the value of alpha increases the variance of the model, making it more prone to overfitting but\n",
    "also increasing its ability to fit the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0fb18-5823-40cf-be8e-f163ea586fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.Ans.\n",
    "\n",
    "Lasso Regression can be used for non-linear regression problems through feature engineering.\n",
    "\n",
    "Feature engineering involves creating new features that capture the non-linear relationships between the\n",
    "features and the target variable. These features can be created by transforming the original features or\n",
    "by combining them in non-linear ways. For example, if the target variable has a non-linear relationship\n",
    "with a feature, such as a quadratic or exponential relationship, we can create new features by taking\n",
    "the square or exponential of that feature. Similarly, we can combine features to capture more complex\n",
    "relationships between them.\n",
    "\n",
    "Once we have created new features that capture the non-linear relationships between the features and the \n",
    "target variable, we can apply Lasso Regression to the transformed data. The regularization strength\n",
    "parameter alpha should be chosen through cross-validation or grid search to balance the tradeoff between \n",
    "bias and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8031ccee-05e3-4ee8-8ae8-6d84ddfcd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.Ans.\n",
    "\n",
    "Regularization technique: Ridge Regression uses L2 regularization, which adds a penalty term to the\n",
    "sum of the squares of the coefficients, while Lasso Regression uses L1 regularization, which adds\n",
    "a penalty term to the sum of the absolute values of the coefficients. This difference in regularization\n",
    "techniques leads to differences in the coefficients' values and the model's behavior.\n",
    "\n",
    "Coefficient shrinkage: In Ridge Regression, the regularization penalty shrinks the coefficients towards\n",
    "zero, but they are never exactly zero. In contrast, in Lasso Regression, the regularization penalty can\n",
    "set some of the coefficients exactly to zero, effectively performing feature selection and reducing the\n",
    "model's complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b4177-e1c2-468b-8bdd-e9b8250fb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.Ans.\n",
    "\n",
    "Lasso Regression can handle multicollinearity in the input features to some extent, but it may not\n",
    "perform as well as Ridge Regression or other regularization techniques specifically designed to handle\n",
    "multicollinearity.\n",
    "\n",
    "Multicollinearity is a common problem in regression analysis when there are high correlations between \n",
    "the input features, leading to unstable and unreliable coefficient estimates. Lasso Regression uses L1 \n",
    "regularization to shrink the coefficients towards zero, effectively performing feature selection and\n",
    "reducing the model's complexity. This regularization technique can help mitigate the effects of\n",
    "multicollinearity by reducing the impact of correlated features in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad54a693-8cbf-4bee-a9a7-d42ee1ee1515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.Ans.\n",
    "\n",
    "In Lasso regression, the regularization parameter (lambda) controls the strength of the \n",
    "penalty applied to the model coefficients. The goal of Lasso regression is to find a sparse\n",
    "model by shrinking some coefficients towards zero. Therefore, the optimal value of lambda is\n",
    "the one that balances the model's ability to fit the data well with the desire to keep the model's complexity \n",
    "low.\n",
    "\n",
    "One way to choose the optimal value of lambda in Lasso regression is through cross-validation.\n",
    "Here are the general steps:\n",
    "\n",
    "Split the data into training and validation sets.\n",
    "Create a range of lambda values to test.\n",
    "For each lambda value, fit the model to the training set and evaluate its performance on the validation \n",
    "set using a metric such as mean squared error (MSE).\n",
    "Choose the lambda value that results in the lowest MSE on the validation set.\n",
    "Finally, re-fit the model using the chosen lambda value on the entire training set.\n",
    "This process can be repeated several times using different training and validation sets to get a more \n",
    "reliable estimate of the optimal lambda value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
